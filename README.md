# local-media-processor

# Обзор

* Транскрипция аудио/видео: Используем faster-whisper (локальная версия Whisper от OpenAI), которая поддерживает множество языков и работает на CPU/GPU.
* OCR для изображений: EasyOCR для распознавания текста на изображениях, поддерживает 80+ языков.
* Перевод текста: transformers от Hugging Face с моделью Helsinki-NLP (Opus-MT) для перевода между языками.
* TTS (текст в голос): TTS от Coqui (поддерживает множество языков, работает на CPU/GPU).
* Интерфейс: Gradio для веб-UI, где пользователь может загружать файлы, выбирать языки и получать результаты.
* Запуск: Через Docker Compose. Контейнер включает все зависимости, модели скачиваются автоматически при первом запуске.
* Локальность: Нет внешних API, всё оффлайн после загрузки моделей.
* GPU/CPU: Автоматически использует GPU, если доступен (через CUDA в Docker).


# Проект состоит из:

* app.py: Основной скрипт с Gradio UI и логикой.
* requirements.txt: Зависимости.
* Dockerfile: Для сборки образа.
* docker-compose.yml: Для запуска.

# Шаги по установке и запуску: 

git clone git@github.com:alexeynickulin-web/local-media-processor.git
docker-compose up --build
http://localhost:7860 (Gradio UI).
Первый запуск может занять время (скачивание моделей ~5-10 ГБ).

UI позволит загружать аудио/видео/изображение, выбирать исходный/целевой язык, и получать транскрипцию + перевод + TTS аудио.
